# Logstash Exmple

## 0. Prerequisite
- 실습에 필요한 라이브러리 설치
```
# Java 설치 및 JAVA_HOME 설정
> sudo yum install -y java
> export JAVA_HOME=$(alternatives --display java | grep current | sed 's/link currently points to //' | sed 's|/bin/java||')
> echo $JAVA_HOME
```

```
> sudo yum install -y wget git
```

## 1. Install
- java가 설치되어 있어야 하며, JAVA_HOME이 환경설정에 추가되어야 한다.
```
>  cd ~
> mkdir apps
> cd apps
> wget https://artifacts.elastic.co/downloads/logstash/logstash-6.4.2.tar.gz
> tar xvf logstash-6.4.2.tar.gz
> cd logstash-6.4.2
```

## 2. Exxamples
- 아래와 같이 input, filter, output을 정의하고, 이를 실행하여 데이터 수집/저장

![quick guide](https://www.elastic.co/guide/en/logstash/current/static/images/basic_logstash_pipeline.png)

### Example 01. Quick guide
- 사용자의 input을 입력으로 받아서 화면에 출력해 보자.
```
> cd ~/apps/logstash-6.4.2
> bin/logstash -e 'input { stdin { } } output { stdout {} }'
hi logstash

# 아래와 같은 메세지가 정상적으로 출력됨
{
          "host" => "kafka-test",
    "@timestamp" => 2018-10-11T08:01:09.496Z,
       "message" => "hi logstash",
      "@version" => "1"
}
```


### Example 02. message parsing using grok filter (apache web server log를 대상)
- 특정 규칙을 가지는 log 파일(web server log 등)을 filter의 grok 플러그인을 활용하여 쉽게 파싱
- 기존에 정의된 APACHE WEB LOG를 파싱하는 pattern인 "COMBINEDAPACHELOG" 적용
- 아래의 링크에 다양한 Pattern이 있으므로, 여기서 선택하여 적용할 수 있다. https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns
```
> cd ~/apps/logstash-6.4.2

# 1) config 파일 생성
> vi logstash-filter.conf
input { stdin { } }
filter {
  grok {
    match => { "message" => "%{COMBINEDAPACHELOG}" }
  }
  date {
    match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]
  }
}
output {
  stdout { codec => rubydebug }
}

# 2) logstash 실행
> bin/logstash -f logstash-filter.conf
# 아래 메세지 입력
127.0.0.1 - - [11/Dec/2013:00:01:45 -0800] "GET /xampp/status.php HTTP/1.1" 200 3891 "http://cadenza/xampp/navi.php" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:25.0) Gecko/20100101 Firefox/25.0"

# 3) 아래와 같이 파싱된 정보가 출력됨
{
      "@version" => "1",
     "timestamp" => "11/Dec/2013:00:01:45 -0800",
          "verb" => "GET",
       "message" => "127.0.0.1 - - [11/Dec/2013:00:01:45 -0800] \"GET /xampp/status.php HTTP/1.1\" 200 3891 \"http://cadenza/xampp/navi.php\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:25.0) Gecko/20100101 Firefox/25.0\"",
         "ident" => "-",
          "host" => "kafka-test",
      "response" => "200",
      "clientip" => "127.0.0.1",
          "auth" => "-",
    "@timestamp" => 2013-12-11T08:01:45.000Z,
         "bytes" => "3891",
   "httpversion" => "1.1",
         "agent" => "\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:25.0) Gecko/20100101 Firefox/25.0\"",
       "request" => "/xampp/status.php",
      "referrer" => "\"http://cadenza/xampp/navi.php\""
}
```

### Example 03. syslog 정보를 수집하여 출력
- syslog는 logstash에서 가장 많이 수집하는 데이터임. (Unix logging standard)
- 이번 예제에서는 logstash 인스턴스에서 5000 port로 syslog 메세지가 받도록 설정하고,
- 실제로는 client에서 telnet을 통해서 syslog 메세지를 임의로 보내도록 해 본다.
```
> cd ~/apps/logstash-6.4.2

# 1) config 파일 생성
> vi syslog.conf
input {
  tcp {
    port => 5000
    type => syslog
  }
  udp {
    port => 5000
    type => syslog
  }
}

filter {
  if [type] == "syslog" {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
      add_field => [ "received_at", "%{@timestamp}" ]
      add_field => [ "received_from", "%{host}" ]
    }
    date {
      match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    }
  }
}

output {
  stdout { codec => rubydebug }
}

# 2) logstash 실행
> bin/logstash -f syslog.conf

# 3) 새로운 terminal 을 열고 아래 telnet으로 syslog 메세지를 직접 전송
> curl telnet://localhost:5000
Trying ::1...
Connected to localhost.
Escape character is '^]'.

Dec 23 12:11:43 louis postfix/smtpd[31499]: connect from unknown[95.75.93.154]
Dec 23 14:42:56 louis named[16000]: client 199.48.164.7#64817: query (cache) 'amsterdamboothuren.com/MX/IN' denied
Dec 23 14:30:01 louis CRON[619]: (www-data) CMD (php /usr/share/cacti/site/poller.php >/dev/null 2>/var/log/cacti/poller-error.log)
Dec 22 18:28:06 louis rsyslogd: [origin software="rsyslogd" swVersion="4.2.0" x-pid="2253" x-info="http://www.rsyslog.com"] rsyslogd was HUPed, type 'lightweight'.

# 4) 출력결과 확인
[2018-10-11T08:20:23,150][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
{
             "message" => "  Dec 23 12:11:43 louis postfix/smtpd[31499]: connect from unknown[95.75.93.154]",
          "syslog_pid" => "31499",
      "syslog_message" => "connect from unknown[95.75.93.154]",
      "syslog_program" => "postfix/smtpd",
         "received_at" => "2018-10-11T08:22:12.478Z",
            "@version" => "1",
     "syslog_hostname" => "louis",
    "syslog_timestamp" => "Dec 23 12:11:43",
                "type" => "syslog",
                "host" => "localhost",
                "port" => 35410,
       "received_from" => "localhost",
          "@timestamp" => 2018-12-23T12:11:43.000Z
}
...

```


### Example 04. syslog 정보를 수집하여 출력
- syslog는 logstash에서 가장 많이 수집하는 데이터임. (Unix logging standard)
- 이번 예제에서는 logstash 인스턴스에서 5000 port로 syslog 메세지가 받도록 설정하고,
- 실제로는 client에서 telnet을 통해서 syslog 메세지를 임의로 보내도록 해 본다.


### Example 05. hdfs output

#### Install webhdfs
```
> yum install curl gcc gcc-c++, readline-devel, zlib-devel, libyaml-devel, libffi-devel, openssl-devel, autoconf, automake, libtool, bison

>  curl -sSL https://get.rvm.io | bash -s stable --ruby
  curl -sSL https://rvm.io/mpapis.asc | gpg --import -
  curl -sSL https://get.rvm.io | bash -s stable --ruby

# 신규 Console 접속
> rvm version
rvm 1.29.4 (latest) by Michal Papis, Piotr Kuczynski, Wayne E. Seguin [https://rvm.io]
> ruby -v
ruby 2.5.1p57 (2018-03-29 revision 63029) [x86_64-linux]
> gem -v
2.7.8

> gem install webhdfs
```


#### webhdfs example
```
# Browser에서 호출
> curl -i -X PUT "http://10.178.253.247:50070/webhdfs/v1/tmp/a.txt?user.name=livy&op=CREATE"
```

#### logstash config 설정 샘플
- file-2-hdsf.yml
```yml
input {
  file {
    path => "/home/rts/tracks_live.csv"  # 로컬 파일 주소
  }
}

output {
  stdout {
    codec => rubydebug{ }
  }
  webhdfs {
    host => "bp01.hadoop.co.kr" # namenode url
    port => 50070               # namenode port
    path => "/tmp/tracks_live.csv" # hdfs 디렉토리 및 파일명
    user => "hdfs"              # 파일 소유자 계정
  }
}
```
#### logstash 실행
- HDFS에 해당 파일이 존재하는지 확인한다.
```
> logstash -f file-2-hdsf.yml  실행
```

### Example kafka to hdfs
```yml
input {
    kafka {
      bootstrap_servers => "bp03:6667,bp04:6667,bp05:6667"
      group_id => "logstash"
      topics => ["test"]
      consumer_threads => 1
    }
}
output {
  stdout {
    codec => rubydebug{ }
  }
  webhdfs {
    host => "bp01.hadoop.co.kr"
    port => 50070
    path => "/tmp/card_hist_init-3.csv"
    user => "hdfs"
    codec => line { format => "%{message}"}
  }
}
```
