# Real-time data pipeline using apache kafka 

## [STEP 0] Prerequisite
- 실습에 필요한 라이브러리 설치
### Java 설치 및 JAVA_HOME 설정
```
> sudo yum install -y java

# 현재 OS 설정이 한글인지 영어인지 확인한다. 
> alternatives --display java

# 아래와 같이 출력되면 한글임. 
슬레이브 unpack200.1.gz: /usr/share/man/man1/unpack200-java-1.8.0-openjdk-1.8.0.312.b07-1.el7_9.x86_64.1.gz
현재 '최고' 버전은 /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.312.b07-1.el7_9.x86_64/jre/bin/java입니다.

### 한글인 경우 
> alternatives --display java | grep '현재 /'| sed "s/현재 //" | sed 's|/bin/java로 링크되어 있습니다||'
> export JAVA_HOME=$(alternatives --display java | grep '현재 /'| sed "s/현재 //" | sed 's|/bin/java로 링크되어 있습니다||')

### 영문인 경우
> alternatives --display java | grep current | sed 's/link currently points to //' | sed 's|/bin/java||' | sed 's/^ //g'
> export JAVA_HOME=$(alternatives --display java | grep current | sed 's/link currently points to //' | sed 's|/bin/java||' | sed 's/^ //g')

# 제대로 java 경로가 설정되었는지 확인
> echo $JAVA_HOME
> echo "export JAVA_HOME=$JAVA_HOME" >> ~/.bash_profile
> source ~/.bash_profile
```


## [STEP 1] Install ELK Stack (Elasticsearch + Logstash + Kibana)
- Elasticsearch를 비즈니에서 활용시 주의사항 (OSS버전 vs Default)
    - OSS는 elasticsearch를 이용하여 별도의 제품/솔루션으로 판매할 목적인 경우에 활용
    - Basic은 기업 내부에서는 무료로 사용가능 
        - 즉 OSS 버전을 기반으로 elastic사에서 추가기능(ML, SIEM등)을 무료로 제공하는 것
    - 정리하면, OSS는 누구나 활용 가능한 오픈소스
        - 이를 이용해 별도의 제품을 만들어도 가능함.
        - elastic사도 OSS를 이용해서 basic 제품을 개발하고, 이를 무료로 제공함. 
        - 하지만, basic 버전의 소유권은 elastic사에 귀속됨(무로지만, 이를 이용해 비즈니스/사업을 하면 안됨)
    - http://kimjmin.net/2020/06/2020-06-elastic-devrel/

### Install an Elasticsearch 
- https://www.elastic.co/guide/en/elastic-stack/current/installing-elastic-stack.html 참고
```
> cd ~/apps
> wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.1-linux-x86_64.tar.gz
> tar -xzf elasticsearch-7.10.1-linux-x86_64.tar.gz
```
- config 설정 
    - 외부 접속 허용(network.host) : server와 client가 다른 ip가 있을 경우, 외부에서 접속할 수 있도록 설정을 추가해야함.
    - master host 설정 (cluster.initial_master_nodes) : Master Node의 후보를 명시하여, Master Node 다운시 새로운 Master로 선출한다.
```
> cd ~/apps/elasticsearch-7.10.1
> vi config/elasticsearch.yml
# bind ip to connect from client  (lan이 여러개 있을 경우 외부에서 접속할 ip를 지정할 수 있음.)
# bind all ip server have "0.0.0.0"

network.host: 0.0.0.0   #(":" 다음에 스페이스를 추가해야 함.)

# Master Node의 후보 서버 목록을 적어준다. (여기서는 1대 이므로 본인의 IP만)
# ip를 입력하면 
cluster.initial_master_nodes: ["서버이름"]
```

#### Error 발생 (cluster.initial_master_nodes에 IP를 입력한 경우)
- 에러 로그 유형
    - skipping cluster bootstrapping as local node does not match bootstrap requirements: [34.64.85.55]
    - master not discovered yet, this node has not previously joined a bootstrapped (v7+) cluster, and [cluster.initial_master_nodes] is empty on this node
- 해결
    - cluster.initial_master_nodes: ["node name"] 입력 

#### run elasticsearch 
```
> cd ~/apps/elasticsearch-7.10.1
> bin/elasticsearch

# 아래와 같은 에러가 발생함. 
ERROR: [3] bootstrap checks failed
[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]
[2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
ERROR: Elasticsearch did not exit normally - check the logs at /home/freepsw/apps/elasticsearch-7.10.1/logs/elasticsearch.log
[2020-12-14T08:16:54,358][INFO ][o.e.n.Node               ] [freepsw-test] stopping ...
[2020-12-14T08:16:54,395][INFO ][o.e.n.Node               ] [freepsw-test] stopped
[2020-12-14T08:16:54,395][INFO ][o.e.n.Node               ] [freepsw-test] closing ...
[2020-12-14T08:16:54,431][INFO ][o.e.n.Node               ] [freepsw-test] closed
```
- Elasticsearch를 실행하기 위해서 필요한 OS 설정이 충족되지 못하여 발생하는 오류 (이를 해결하기 위한 설정 변경)
#### 오류1) File Descriptor 오류 해결
- file descriptor 갯수를 증가시켜야 한다.
- 에러 : [1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]
- https://www.elastic.co/guide/en/elasticsearch/reference/current/setting-system-settings.html#limits.conf
```
> sudo vi /etc/security/limits.conf
# 아래 내용 추가 
* hard nofile 70000
* soft nofile 70000
root hard nofile 70000
root soft nofile 70000

# 적용을 위해 콘솔을 닫고 다시 연결한다. (console 재접속)
# 적용되었는지 확인
> ulimit -a
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 59450
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 70000  #--> 정상적으로 적용됨을 확인함
```

#### 오류2) virtual memory error 해결
- 시스템의 nmap count를 증가기켜야 한다.
- 에러 : [2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
- https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html
```
# 0) 현재 설정 값 확인
> cat /proc/sys/vm/max_map_count
65530

# 아래 3가지 방법 중 1가지를 선택하여 적용 가능
# 1-1) 현재 서버상태에서만 적용하는 방식
> sudo sysctl -w vm.max_map_count=262144

# 1-2) 영구적으로 적용 (서버 재부팅시 자동 적용)
> sudo vi /etc/sysctl.conf

# 아래 내용 추가
vm.max_map_count = 262144

# 1-3) 또는 아래 명령어 실행 
> echo vm.max_map_count=262144 | sudo tee -a /etc/sysctl.conf


# 3) 시스템에 적용하여 변경된 값을 확인
> sudo sysctl -p
vm.max_map_count = 262144
```

- rerun elasticsearch 
```
> cd ~/apps/elasticsearch-7.10.1
> bin/elasticsearch
......
[2020-12-14T10:18:18,803][INFO ][o.e.l.LicenseService     ] [freepsw-test] license [944a4695-3ec0-41f1-b3f8-5752b71c759e] mode [basic] - valid
[2020-12-14T10:18:18,806][INFO ][o.e.x.s.s.SecurityStatusChangeListener] [freepsw-test] Active license is now [BASIC]; Security is disabled
```

#### Elasticsearch UI로 접속하기 
- 1) 웹브라우저에서 접속 확인 
    - http://VM외부IP:9200
- 2) Elasticsearch용 시각화 plugin(elasticsearch head) 설치 (구글 크롬 브라우저)
    - https://chrome.google.com/webstore/detail/elasticsearch-head/ffmkiejjmecolpfloofpjologoblkegm
    - "Chrome에 추가" 클릭
    - 추가된 Plugin 클릭하여 접속 > "Elasticsearch 설치된 IP입력" > Connect 버튼 클릭


### Install and run a kibana 
```
> cd ~/apps
> curl -O https://artifacts.elastic.co/downloads/kibana/kibana-7.10.1-linux-x86_64.tar.gz
> tar -xzf kibana-7.10.1-linux-x86_64.tar.gz
> cd kibana-7.10.1-linux-x86_64/

# 외부 접속 가능하도록 설정 값 변경 
# 외부의 어떤 IP에서도 접속 가능하도록 0.0.0.0으로 변경 (운영환경에서는 특정 ip대역만 지정하여 보안강화)
> vi config/kibana.yml
server.host: "0.0.0.0"


> cd ~/apps/kibana-7.10.1-linux-x86_64/
> bin/kibana
.....
  log   [10:40:10.296] [info][server][Kibana][http] http server running at http://localhost:5601
  log   [10:40:12.690] [warning][plugins][reporting] Enabling the Chromium sandbox provides an additional layer of protection
```

#### Kibana 에러 시 기존 index 삭제 후 재시작
```
curl -XDELETE http://localhost:9200/.kibana
curl -XDELETE 'http://localhost:9200/.kibana*'
curl -XDELETE http://localhost:9200/.kibana_2
curl -XDELETE http://localhost:9200/.kibana_1
```


### Install a logstash 
```
> cd ~/apps
> wget https://artifacts.elastic.co/downloads/logstash/logstash-7.10.1-linux-x86_64.tar.gz
> tar xvf logstash-7.10.1-linux-x86_64.tar.gz
> cd logstash-7.10.1
```
- Test a logstash 
```
> bin/logstash -e 'input { stdin { } } output { stdout {} }'
# 실행까지 시간이 소요된다. (아래 메세지가 출력되면 정상 실행된 것으로 확인)
.........
The stdin plugin is now waiting for input:
[2020-12-20T08:20:58,728][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2020-12-20T08:20:59,146][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
mytest  <-- 메세지 입력 후 아래와 같이 출력되면 정상적으로 설치된 것
{
       "message" => "mytest",
      "@version" => "1",
          "host" => "freepsw-test",
    "@timestamp" => 2020-12-14T10:51:12.408Z
}
```


## [STEP 2] Install & start kafka [link](http://kafka.apache.org/documentation.html#quickstart)
###  Step 1: Download the code
```
> cd ~/apps/
> wget https://archive.apache.org/dist/kafka/3.0.0/kafka_2.12-3.0.0.tgz
> tar xvf kafka_2.12-3.0.0.tgz

> cd ~/apps/kafka_2.12-3.0.0
- edit kafka config (server.config)
    - 외부에서 apache kafka 접속할 수 있도록 설정
    - 아래 "서버IP"를 kafka가 실행중인 서버 IP로 변경한다.
    - Host name으로 설정하려는 경우, 외부에서 접속 가능한 host명이어야 한다. (DNS에 등록된 hostname)
    - 즉, 외부에서 kafka에 접속 할 수 있는 정보를 입력해야 함.

> cd ~/apps/kafka_2.12-2.6.0
> vi config/server.properties
advertised.listeners=PLAINTEXT://서버IP:9092 
```

### Step 2: Start Zookeeper server
```
# 1) Foreground 실행 (테스트 용으로 zookeeper 로그를 직접 확인)
> bin/zookeeper-server-start.sh config/zookeeper.properties

# 2) Background 실행
> bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
> ps -ef | grep zookeeper
```

### Step 3: Start Kafka server
-  kafka delete option 설정
  - topic을 삭제할 수 있는 옵션 추가 (운영서버에서는 이 옵션을 false로 설정. topic을 임의로 삭제할 수 없도록)
```
> cd ~/apps/kafka_2.12-3.0.0
> vi config/server.properties
  # 아래 내용 추가
  delete.topic.enable=true

# 1) Foregroud 
> bin/kafka-server-start.sh config/server.properties

# 2) background 실행
> bin/kafka-server-start.sh -daemon config/server.properties
```


### Step 4: Create a topic (realtime)
- 실습에 사용할 topic을 생성한다. 
```
> cd ~/apps/kafka_2.12-3.0.0

> bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic realtime
# check created topic "realtime"
> bin/kafka-topics.sh --list --bootstrap-server localhost:9092
realtime
```


### Step 5: Send some messages
```
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic realtime
This is a message
This is another message
```

### Step 6: Start a consumer
```
> cd ~/apps/kafka_2.12-3.0.0
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic realtime --from-beginning

This is a message
This is another message
```


## [STEP 3] Run the Kakfka Producer using logstash 

### download the sample file
```
> cd ~/apps
> wget https://github.com/freepsw/demo-spark-analytics/raw/master/00.stage1/tracks.csv
```
### Run logstash 
- kafka topic을 realtime로 변경
```
> vi ~/apps/producer.conf
```
```yaml
input {
  file {
    path => "/home/freepsw/apps/tracks_live.csv"
  }
}

output {
  stdout {
    codec => rubydebug{ }
  }

  kafka {
    codec => plain {
      format => "%{message}"
    }
    bootstrap_servers => "localhost:9092"
    topic_id => "realtime"
  }
}

```

- run logstash 
```
> cd ~/apps/
> ~/apps/logstash-7.10.1/bin/logstash -f producer.conf
```

- check received message from kafka using kafka-console_consumer
    - logstash에서 kafka로 정상적으로 메세지가 전송되고 있는지 모니터링
    - 아래의 kafka-console-consumer 명령어를 통해 전송되는 메세지를 확인
```
> cd ~/apps/kafka_2.12-3.0.0
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic realtime
# logstash에서 정상적으로 메세지를 보내면, 아래와 같은 메세지가 출력될 것임.
0,48,453,"2014-10-23 03:26:20",0,"72132"
1,1081,19,"2014-10-15 18:32:14",1,"17307"
2,532,36,"2014-12-10 15:33:16",1,"66216
```


## [STEP 4] Generate steaming data using data-generator.py
```
> cd ~/apps
> vi data_generator.py
```
### data_generator.py
```python
#-*- coding: utf-8 -*-
import time
import random

r_fname = "tracks.csv"
w_fname = "tracks_live.csv"

rf = open(r_fname)
wf = open(w_fname, "a+")

try:
	num_lines = sum(1 for line in rf)
	print(num_lines)
	#num_lines = 10

	rf.seek(0)
	lines = 0
	while (1):
		line = rf.readline()
		wf.write(line)
		wf.flush()

		# sleep for weighted time period
		stime = random.choice([1, 1, 1, 0.5, 0.5, 0.8, 0.3, 2, 0.1, 3])
		print(stime)
		time.sleep(stime)
		lines += 1

		# exit if read all lines
		if(lines == num_lines):
			break
		# if(lines == num_lines):
		# 	rf.seek(0)
finally:
	rf.close()
	wf.close()
	print("close file")
```

### run generator 
```
> cd ~/apps
> python data_generator.py
```

### Check kafka message
```
> cd ~/apps/kafka_2.12-3.0.0
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic realtime
# logstash에서 정상적으로 메세지를 보내면, 아래와 같은 메세지가 출력될 것임.
0,48,453,"2014-10-23 03:26:20",0,"72132"
1,1081,19,"2014-10-15 18:32:14",1,"17307"
2,532,36,"2014-12-10 15:33:16",1,"66216
```


## [STEP 5] Run the Kakfka Consumer using logstash
```
> cd ~/apps
> vi ~/apps/consumer.conf
```
```yaml
input {
  kafka{
    topics => ["realtime"]
    bootstrap_servers => "localhost:9092"
  }
}

output {
  stdout { codec => rubydebug }

  elasticsearch {
    hosts => "http://localhost:9200"
    index => "ba_realtime"
  }
} 
```

### run logstash consumer 
```
> cd ~/apps
> ~/apps/logstash-7.10.1/bin/logstash -f consumer.conf

~/apps/logstash-7.10.1/bin/logstash --path.data ~/apps/consumer-data -f ~/apps/consumer.conf
```


## [STEP 6] Kibana로 실시간 유입 데이터 확인
### Web Browser에서 접속하여 데이터 확인
- http://vm-instance-ip:5601 

