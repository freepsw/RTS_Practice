# Data Message Queue (Apache Kafka)

## [STEP 0] Prerequisite
- 실습에 필요한 라이브러리 설치
### Java 설치 및 JAVA_HOME 설정
```
> sudo yum install -y java

# 현재 OS 설정이 한글인지 영어인지 확인한다. 
> alternatives --display java

# 아래와 같이 출력되면 한글임. 
슬레이브 unpack200.1.gz: /usr/share/man/man1/unpack200-java-1.8.0-openjdk-1.8.0.312.b07-1.el7_9.x86_64.1.gz
현재 '최고' 버전은 /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.312.b07-1.el7_9.x86_64/jre/bin/java입니다.

### 한글인 경우 
> alternatives --display java | grep '현재 /'| sed "s/현재 //" | sed 's|/bin/java로 링크되어 있습니다||'
> export JAVA_HOME=$(alternatives --display java | grep '현재 /'| sed "s/현재 //" | sed 's|/bin/java로 링크되어 있습니다||')

### 영문인 경우
> alternatives --display java | grep current | sed 's/link currently points to //' | sed 's|/bin/java||' | sed 's/^ //g'
> export JAVA_HOME=$(alternatives --display java | grep current | sed 's/link currently points to //' | sed 's|/bin/java||' | sed 's/^ //g')

# 제대로 java 경로가 설정되었는지 확인
> echo $JAVA_HOME
> echo "export JAVA_HOME=$JAVA_HOME" >> ~/.bash_profile
> source ~/.bash_profile
```


## [STEP 1] Install ELK Stack (Elasticsearch + Logstash + Kibana)
- Elasticsearch를 비즈니에서 활용시 주의사항 (OSS버전 vs Default)
    - OSS는 elasticsearch를 이용하여 별도의 제품/솔루션으로 판매할 목적인 경우에 활용
    - Basic은 기업 내부에서는 무료로 사용가능 
        - 즉 OSS 버전을 기반으로 elastic사에서 추가기능(ML, SIEM등)을 무료로 제공하는 것
    - 정리하면, OSS는 누구나 활용 가능한 오픈소스
        - 이를 이용해 별도의 제품을 만들어도 가능함.
        - elastic사도 OSS를 이용해서 basic 제품을 개발하고, 이를 무료로 제공함. 
        - 하지만, basic 버전의 소유권은 elastic사에 귀속됨(무로지만, 이를 이용해 비즈니스/사업을 하면 안됨)
    - http://kimjmin.net/2020/06/2020-06-elastic-devrel/

### Install an Elasticsearch 
- https://www.elastic.co/guide/en/elastic-stack/current/installing-elastic-stack.html 참고
```
> cd ~/apps
> wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.1-linux-x86_64.tar.gz
> tar -xzf elasticsearch-7.10.1-linux-x86_64.tar.gz
```
- config 설정 
    - 외부 접속 허용(network.host) : server와 client가 다른 ip가 있을 경우, 외부에서 접속할 수 있도록 설정을 추가해야함.
    - master host 설정 (cluster.initial_master_nodes) : Master Node의 후보를 명시하여, Master Node 다운시 새로운 Master로 선출한다.
        - 
```
> cd ~/apps/elasticsearch-7.10.1
> vi config/elasticsearch.yml
# bind ip to connect from client  (lan이 여러개 있을 경우 외부에서 접속할 ip를 지정할 수 있음.)
# bind all ip server have "0.0.0.0"

network.host: 0.0.0.0   #(":" 다음에 스페이스를 추가해야 함.)

# Master Node의 후보 서버 목록을 적어준다. (여기서는 1대 이므로 본인의 IP만)
# ip를 입력하면 
cluster.initial_master_nodes: ["서버이름"]
```

#### Error 발생 (cluster.initial_master_nodes에 IP를 입력한 경우)
- 에러 로그 유형
    - skipping cluster bootstrapping as local node does not match bootstrap requirements: [34.64.85.55]
    - master not discovered yet, this node has not previously joined a bootstrapped (v7+) cluster, and [cluster.initial_master_nodes] is empty on this node
- 해결
    - cluster.initial_master_nodes: ["node name"] 입력 

#### run elasticsearch 
```
> cd ~/apps/elasticsearch-7.10.1
> bin/elasticsearch

# 아래와 같은 에러가 발생함. 
ERROR: [3] bootstrap checks failed
[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]
[2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
ERROR: Elasticsearch did not exit normally - check the logs at /home/freepsw/apps/elasticsearch-7.10.1/logs/elasticsearch.log
[2020-12-14T08:16:54,358][INFO ][o.e.n.Node               ] [freepsw-test] stopping ...
[2020-12-14T08:16:54,395][INFO ][o.e.n.Node               ] [freepsw-test] stopped
[2020-12-14T08:16:54,395][INFO ][o.e.n.Node               ] [freepsw-test] closing ...
[2020-12-14T08:16:54,431][INFO ][o.e.n.Node               ] [freepsw-test] closed
```
- Elasticsearch를 실행하기 위해서 필요한 OS 설정이 충족되지 못하여 발생하는 오류 (이를 해결하기 위한 설정 변경)
#### 오류1) File Descriptor 오류 해결
- file descriptor 갯수를 증가시켜야 한다.
- 에러 : [1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]
- https://www.elastic.co/guide/en/elasticsearch/reference/current/setting-system-settings.html#limits.conf
```
> sudo vi /etc/security/limits.conf
# 아래 내용 추가 
* hard nofile 70000
* soft nofile 70000
root hard nofile 70000
root soft nofile 70000

# 적용을 위해 콘솔을 닫고 다시 연결한다. (console 재접속)
# 적용되었는지 확인
> ulimit -a
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 59450
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 70000  #--> 정상적으로 적용됨을 확인함
```

#### 오류2) virtual memory error 해결
- 시스템의 nmap count를 증가기켜야 한다.
- 에러 : [2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
- https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html
```
# 0) 현재 설정 값 확인
> cat /proc/sys/vm/max_map_count
65530

# 아래 3가지 방법 중 1가지를 선택하여 적용 가능
# 1-1) 현재 서버상태에서만 적용하는 방식
> sudo sysctl -w vm.max_map_count=262144

# 1-2) 영구적으로 적용 (서버 재부팅시 자동 적용)
> sudo vi /etc/sysctl.conf

# 아래 내용 추가
vm.max_map_count = 262144

# 1-3) 또는 아래 명령어 실행 
> echo vm.max_map_count=262144 | sudo tee -a /etc/sysctl.conf


# 3) 시스템에 적용하여 변경된 값을 확인
> sudo sysctl -p
vm.max_map_count = 262144
```

- rerun elasticsearch 
```
> cd ~/apps/elasticsearch-7.10.1
> bin/elasticsearch
......
[2020-12-14T10:18:18,803][INFO ][o.e.l.LicenseService     ] [freepsw-test] license [944a4695-3ec0-41f1-b3f8-5752b71c759e] mode [basic] - valid
[2020-12-14T10:18:18,806][INFO ][o.e.x.s.s.SecurityStatusChangeListener] [freepsw-test] Active license is now [BASIC]; Security is disabled
```

#### Elasticsearch UI로 접속하기 
- 1) 웹브라우저에서 접속 확인 
    - http://VM외부IP:9200
- 2) Elasticsearch용 시각화 plugin(elasticsearch head) 설치 (구글 크롬 브라우저)
    - https://chrome.google.com/webstore/detail/elasticsearch-head/ffmkiejjmecolpfloofpjologoblkegm
    - "Chrome에 추가" 클릭
    - 추가된 Plugin 클릭하여 접속 > "Elasticsearch 설치된 IP입력" > Connect 버튼 클릭


### Install and run a kibana 
```
> cd ~/apps
> curl -O https://artifacts.elastic.co/downloads/kibana/kibana-7.10.1-linux-x86_64.tar.gz
> tar -xzf kibana-7.10.1-linux-x86_64.tar.gz
> cd kibana-7.10.1-linux-x86_64/

# 외부 접속 가능하도록 설정 값 변경 
# 외부의 어떤 IP에서도 접속 가능하도록 0.0.0.0으로 변경 (운영환경에서는 특정 ip대역만 지정하여 보안강화)
> vi config/kibana.yml
server.host: "0.0.0.0"


> cd ~/apps/kibana-7.10.1-linux-x86_64/
> bin/kibana
.....
  log   [10:40:10.296] [info][server][Kibana][http] http server running at http://localhost:5601
  log   [10:40:12.690] [warning][plugins][reporting] Enabling the Chromium sandbox provides an additional layer of protection
```

#### Kibana 에러 시 기존 index 삭제 후 재시작
```
curl -XDELETE http://localhost:9200/.kibana
curl -XDELETE 'http://localhost:9200/.kibana*'
curl -XDELETE http://localhost:9200/.kibana_2
curl -XDELETE http://localhost:9200/.kibana_1
```


### Install a logstash 
```
> cd ~/apps
> wget https://artifacts.elastic.co/downloads/logstash/logstash-7.10.1-linux-x86_64.tar.gz
> tar xvf logstash-7.10.1-linux-x86_64.tar.gz
> cd logstash-7.10.1
```
- Test a logstash 
```
> bin/logstash -e 'input { stdin { } } output { stdout {} }'
# 실행까지 시간이 소요된다. (아래 메세지가 출력되면 정상 실행된 것으로 확인)
.........
The stdin plugin is now waiting for input:
[2020-12-20T08:20:58,728][INFO ][logstash.agent           ] Pipelines running {:count=>1, :running_pipelines=>[:main], :non_running_pipelines=>[]}
[2020-12-20T08:20:59,146][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=>9600}
mytest  <-- 메세지 입력 후 아래와 같이 출력되면 정상적으로 설치된 것
{
       "message" => "mytest",
      "@version" => "1",
          "host" => "freepsw-test",
    "@timestamp" => 2020-12-14T10:51:12.408Z
}
```


## [STEP 2] Install & start kafka [link](http://kafka.apache.org/documentation.html#quickstart)
###  Step 1: Download the code
```
> cd ~/apps/
> wget https://archive.apache.org/dist/kafka/3.0.0/kafka_2.12-3.0.0.tgz
> tar xvf kafka_2.12-3.0.0.tgz

> cd ~/apps/kafka_2.12-3.0.0
- edit kafka config (server.config)
    - 외부에서 apache kafka 접속할 수 있도록 설정
    - 아래 "서버IP"를 kafka가 실행중인 서버 IP로 변경한다.
    - Host name으로 설정하려는 경우, 외부에서 접속 가능한 host명이어야 한다. (DNS에 등록된 hostname)
    - 즉, 외부에서 kafka에 접속 할 수 있는 정보를 입력해야 함.

> cd ~/apps/kafka_2.12-2.6.0
> vi config/server.properties
advertised.listeners=PLAINTEXT://서버IP:9092 
```

### Step 2: Start Zookeeper server
```
# 1) Foreground 실행 (테스트 용으로 zookeeper 로그를 직접 확인)
> bin/zookeeper-server-start.sh config/zookeeper.properties

# 2) Background 실행
> bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
> ps -ef | grep zookeeper
```

### Step 3: Start Kafka server
-  kafka delete option 설정
  - topic을 삭제할 수 있는 옵션 추가 (운영서버에서는 이 옵션을 false로 설정. topic을 임의로 삭제할 수 없도록)
```
> cd ~/apps/kafka_2.12-3.0.0
> vi config/server.properties
  # 아래 내용 추가
  delete.topic.enable=true

# 1) Foregroud 
> bin/kafka-server-start.sh config/server.properties

# 2) background 실행
> bin/kafka-server-start.sh -daemon config/server.properties
```


### Step 4: Create a topic (realtime)
- 실습에 사용할 topic을 생성한다. 
```
> cd ~/apps/kafka_2.12-3.0.0

> bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic realtime
# check created topic "realtime"
> bin/kafka-topics.sh --list --bootstrap-server localhost:9092
realtime
```


### Step 5: Send some messages
```
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic realtime
This is a message
This is another message
```

### Step 6: Start a consumer
```
> cd ~/apps/kafka_2.12-3.0.0
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic realtime --from-beginning

This is a message
This is another message
```


## [STEP 3] Run the Kakfka Producer using logstash 

### download the sample file
```
> wget https://github.com/freepsw/demo-spark-analytics/raw/master/00.stage1/tracks.csv
```
### Run logstash 
- kafka topic을 realtime로 변경
```
> vi ~/apps/producer.conf
```
```yaml
input {
  file {
    path => "/home/freepsw/apps/tracks_live.csv"
  }
}

output {
  stdout {
    codec => rubydebug{ }
  }

  kafka {
    codec => plain {
      format => "%{message}"
    }
    bootstrap_servers => "localhost:9092"
    topic_id => "realtime"
  }
}

```

- run logstash 
```
> cd ~/apps/
> ~/apps/logstash-7.10.1/bin/logstash -f producer.conf
```

- check received message from kafka using kafka-console_consumer
    - logstash에서 kafka로 정상적으로 메세지가 전송되고 있는지 모니터링
    - 아래의 kafka-console-consumer 명령어를 통해 전송되는 메세지를 확인
```
> cd ~/apps/kafka_2.12-3.0.0
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic realtime
# logstash에서 정상적으로 메세지를 보내면, 아래와 같은 메세지가 출력될 것임.
0,48,453,"2014-10-23 03:26:20",0,"72132"
1,1081,19,"2014-10-15 18:32:14",1,"17307"
2,532,36,"2014-12-10 15:33:16",1,"66216
```


## [STEP 4] Run the Kakfka Consumer using logstash
```
> vi ~/apps/consumer.conf
```
```yaml
input {
  kafka{
  	topics => ["realtime"]
  	bootstrap_servers => "localhost:9092"
  }
}

output {
  stdout { codec => rubydebug }

  elasticsearch {
    hosts => "http://localhost:9200"
    index => "ba_realtime"
  }
} 


```

- run logstash 
```
> cd ~/apps
> ~/apps/logstash-7.10.1/bin/logstash -f consumer.conf
```





















### Step 7: Describe Topic
```
> bin/kafka-topics.sh --describe --bootstrap-server localhost:9092 --topic realtime
Topic:realtime      PartitionCount:1        ReplicationFactor:1     Configs:
        Topic: realtime     Partition: 0    Leader: 0       Replicas: 0     Isr: 0
```

### Steo 8: Offset monitoring
- https://kafka.apache.org/documentation/#basic_ops_consumer_lag
```
# find consumer group list
> bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list
console-consumer-19344

# view offset of group
> bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group console-consumer-19344

TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                     HOST            CLIENT-ID
test            0          2               2               0               consumer-1-ff412a90-fec0-45e4-89d9-06179c7bd8e3 /10.146.0.6     consumer-1
```

### Delete Topic
```
> bin/kafka-topics.sh --delete --zookeeper localhost:2181  --topic streams-file-input
```


## 3. Collect data using apache flume , apache kafka, logstash

### 01. Create Kafka topic
```
> cd ~/apps/kafka_2.12-3.0.0
> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic mytopic

> bin/kafka-topics.sh --list --zookeeper localhost:2181
```

### 02. Collect logs and send logs to kafka using apache flume
- 아래 링크를 이용하여 Apache flume을 설치 및 실행 테스트
- https://github.com/freepsw/RTS_Practice/blob/master/01.Apache%20Flume.md#1-collectionapache-flume
#### Create Flume config

```
> cd ~/apps/apache-flume-1.8.0-bin/conf
> vi nc-kafka.conf

a1.sources = r1
a1.channels = c1
a1.sinks = s1

a1.sources.r1.type = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 56565
a1.sources.r1.channels = c1

a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100

a1.sinks.s1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.s1.topic = mytopic
a1.sinks.s1.brokerList = localhost:9092
a1.sinks.s1.requiredAcks = 1
a1.sinks.s1.batchSize = 20
a1.sinks.s1.channel = c1
```

#### run flume agent
```
> cd ~/apps/apache-flume-1.8.0-bin/
> ./bin/flume-ng agent -c ./conf -f ./conf/nc-kafka.conf -name a1 -Dflume.root.logger=INFO,console
```

### 03. Consume Kafka message using logstash

#### Create logstash config
```
> cd ~/apps/logstash-6.4.2
> vi kafka-input.conf

input {
  kafka{
  	topics => ["토픽명"]
  	bootstrap_servers => "kafka브로커ip:9092"
  }
}

output {
  stdout { codec => rubydebug }
}
```
- logstash 실행

### 04. Send Logs to apache flume using necat command
```
> curl telnet://localhost:56565
hi message
OK
```


### 05. Check logstash console
- 아래와 같이 necat으로 보낸 메세지를 받는지 확인한다.
```json
{
       "message" => "hi message",
      "@version" => "1",
    "@timestamp" => 2018-10-12T14:18:36.953Z
}
```

#### 06. KafkaOffsetMonitoring
- Kafka의 주요 topic, consumer group, offset 값을 모니터링 한다.
- https://github.com/Morningstar/kafka-offset-monitor 참고
```
> cd ~/apps/apache-flume-1.8.0-bin/
> wget https://github.com/Morningstar/kafka-offset-monitor/releases/download/0.4.6/KafkaOffsetMonitor-assembly-0.4.6-SNAPSHOT.jar
> java -cp KafkaOffsetMonitor-assembly-0.4.6-SNAPSHOT.jar \
      com.quantifind.kafka.offsetapp.OffsetGetterWeb \
    --offsetStorage kafka \
    --kafkaBrokers localhost:9092 \
    --zk localhost:2181 \
    --port 8081 \
    --refresh 10.seconds \
    --retain 2.days
```

## 10. Use Kafka Connect to import/export data
- 별도의 수집용 code를 만들지 않고, kafka connect를 이용하여 데이터 import 및 export 할 수 있다.
- Secenario : file을 import하고, file로 export 한다.
```
#  creating some seed data to test with
> echo -e "foo\nbar" > test.txt

# start two connectors running in standalone mode
# 3개의 config 파일을 파라미터로 넘긴다.
# 1. Kafka connect process용 config (broker info, data format ...)
# 2. source에 대한 config (test.txt 지정)
# 3. sink에 대한 config (test.sink.txt 지정)
> bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties

# check test.sink.txt file
> cat test.sink.txt
foo
bar

# send another message
> echo "Another line" >> test.txt

# check test.sink.txt file again


# check kafka topic message
> bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic connect-test --from-beginning

```
## 20. Use Kafka Streams to process data
```
# create message and publish to topic "streams-file-input"
> cd $KAFKA_HOME
> echo -e "all streams lead to kafka\nhello kafka streams\njoin kafka summit" > file-input.txt
> cat file-input.txt | ./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic streams-file-input

# run kafka stream
> ./bin/kafka-run-class.sh org.apache.kafka.streams.examples.wordcount.WordCountDemo

# check result of kafka stream
> ./bin/kafka-console-consumer.sh --zookeeper localhost:2181 \
            --topic streams-wordcount-output \
            --from-beginning \
            --formatter kafka.tools.DefaultMessageFormatter \
            --property print.key=true \
            --property print.key=true \
            --property key.deserializer=org.apache.kafka.common.serialization.StringDeserializer \
            --property value.deserializer=org.apache.kafka.common.serialization.LongDeserializer

all     1
streams 1
lead    1
to      1
kafka   1
hello   1
kafka   2
streams 2
join    1
kafka   3
summit  1

```
